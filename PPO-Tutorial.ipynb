{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0835d0b9",
   "metadata": {},
   "source": [
    "## PPO Implementation Tutorial for Reinforcement Learning\n",
    "Implementating reinforcement learning utilizing the PPO principle from a tutorial so that I can gain a better understanding of how this works to implement it in our final project.\n",
    "\n",
    "Tutorial is very long, and I am taking as much time to fully understand the concepts.\n",
    "By using a jupyter notebook, I can take notes while also checking that everything compiles as I work through the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa23cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up neural network module\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "\n",
    "    # defining neural network laers\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.layer1 = nn.Liner(in_dim, 64)\n",
    "        self.layer2 = nn.Linear(64, 64)\n",
    "        self.layer3 = nn.Linear(64, out_dim)\n",
    "\n",
    "    # the network module defines our actor and critic\n",
    "    # will take in an observation adn return either an action or a value\n",
    "    def forward(self, obs):\n",
    "        # convert observation to tensor if it's a numpy array\n",
    "        if isinstance(obs, np.ndarray):\n",
    "            obs = torch.tensor(obs, dtype=torch.float)\n",
    "        \n",
    "        activation1 = F.relu(self.layer1(obs))\n",
    "        activation2 = F.relu(self.layer2(activation1))\n",
    "        output = self.layer3(activation2)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f772896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import MultivariateNormal\n",
    "from network import FeedForwardNN\n",
    "\n",
    "class PPO:\n",
    "    def __init__(self, env):\n",
    "        #extract environment information\n",
    "        self.env = env\n",
    "        self.obs_dim = env.observation_space.shape[0]\n",
    "        self.act_dim = env.action_space.shape[0]\n",
    "\n",
    "        # initialize actor and critic networks\n",
    "        self.actor = FeedForwardNN(self.obs_dim, self.act_dim)\n",
    "        self.critic = FeedForwardNN(self.obs_dim, 1)\n",
    "\n",
    "        self.cov_var = torch.full(size=(self.act_dim,), fill_value=0.5)\n",
    "        self.cov_mat = torch.diag(self.cov_var)\n",
    "\n",
    "    def rollout(self):\n",
    "        # batch data\n",
    "        batch_obs = []\n",
    "        batch_acts = []\n",
    "        batch_log_probs = []\n",
    "        batch_rews = []\n",
    "        batch_rtgs = []\n",
    "        batch_lens = []\n",
    "\n",
    "        return batch_obs, batch_acts, batch_log_probs, batch_rews, batch_rtgs, batch_lens\n",
    "\n",
    "    def learn(self, total_timesteps):\n",
    "        t_so_far = 0\n",
    "        while t_so_far < total_timesteps:\n",
    "            batch_obs, batch_acts, batch_log_probs, batch_rtgs, batch_lens = self.rollout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
